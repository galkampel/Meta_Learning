{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS330_Homework2_Stencil_TF2.0.ipynb","provenance":[{"file_id":"1zbt2A74kM10HvcAEgEy3fGgRSNyHZQKj","timestamp":1629824761089},{"file_id":"1esHcdn0jL8an4SMG23_fMjbK9n-MsWXz","timestamp":1601876029717},{"file_id":"1lnvSzcjmmJknvRG05fk1BMis7fyE0i9C","timestamp":1601844968812},{"file_id":"1yz-_veyTWMbt3pE1SFyWH-ZoA_AqiImd","timestamp":1601781455461},{"file_id":"13qcZDBvQzxXshmMspv0SBJm9-85GRO31","timestamp":1601644081170}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JvkoC8rAYBE7"},"source":["\n","##Setup\n","\n","You will need to make a copy of this Colab notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**.\n"]},{"cell_type":"code","metadata":{"id":"RBkP5aBdfFkd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632646871603,"user_tz":-180,"elapsed":24439,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"55c2f68c-8ab9-4da8-ee47-030bfc4ef253"},"source":["import os\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","# Need to download the Omniglot dataset -- DON'T MODIFY THIS CELL\n","if not os.path.isdir('./omniglot_resized'):\n","    gdd.download_file_from_google_drive(file_id='1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI',\n","                                        dest_path='./omniglot_resized.zip',\n","                                        unzip=True)\n","\n","assert os.path.isdir('./omniglot_resized')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading 1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI into ./omniglot_resized.zip... Done.\n","Unzipping...Done.\n"]}]},{"cell_type":"code","metadata":{"id":"DMtiYUiwI-1K"},"source":["\"\"\" Utility functions. \"\"\"\n","## NOTE: You do not need to modify this block but you will need to use it.\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","\n","\n","## Loss utilities\n","def cross_entropy_loss(pred, label, k_shot):\n","    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=tf.stop_gradient(label)) / k_shot)\n","\n","def accuracy(labels, predictions):\n","  return tf.reduce_mean(tf.cast(tf.equal(labels, predictions), dtype=tf.float32))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJRiZhJ59CVd"},"source":["# gpus = tf.config.list_physical_devices(\"GPU\")\n","# # if gpus:\n","# #   tf.config.experimental.set_memory_growth(gpus[0], True)\n","# tf.config.experimental.get_memory_growth(gpus[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_dTnU8JwWWc"},"source":["\"\"\"Convolutional layers used by MAML model.\"\"\"\n","## NOTE: You do not need to modify this block but you will need to use it.\n","seed = 123\n","def conv_block(inp, cweight, bweight, bn, activation=tf.nn.relu, residual=False):\n","  \"\"\" Perform, conv, batch norm, nonlinearity, and max pool \"\"\"\n","  stride, no_stride = [1,2,2,1], [1,1,1,1]\n","\n","  conv_output = tf.nn.conv2d(input=inp, filters=cweight, strides=no_stride, padding='SAME') + bweight\n","  normed = bn(conv_output)\n","  normed = activation(normed)\n","  return normed\n","\n","class ConvLayers(tf.keras.layers.Layer):\n","  def __init__(self, channels, dim_hidden, dim_output, img_size):\n","    super(ConvLayers, self).__init__()\n","    self.channels = channels\n","    self.dim_hidden = dim_hidden\n","    self.dim_output = dim_output\n","    self.img_size = img_size\n","\n","    weights = {}\n","\n","    dtype = tf.float32\n","    weight_initializer =  tf.keras.initializers.GlorotUniform()\n","    k = 3\n","\n","    weights['conv1'] = tf.Variable(weight_initializer(shape=[k, k, self.channels, self.dim_hidden]), name='conv1', dtype=dtype)\n","    weights['b1'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b1')\n","    self.bn1 = tf.keras.layers.BatchNormalization(name='bn1')\n","    weights['conv2'] = tf.Variable(weight_initializer(shape=[k, k, self.dim_hidden, self.dim_hidden]), name='conv2', dtype=dtype)\n","    weights['b2'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b2')\n","    self.bn2 = tf.keras.layers.BatchNormalization(name='bn2')\n","    weights['conv3'] = tf.Variable(weight_initializer(shape=[k, k, self.dim_hidden, self.dim_hidden]), name='conv3', dtype=dtype)\n","    weights['b3'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b3')\n","    self.bn3 = tf.keras.layers.BatchNormalization(name='bn3')\n","    weights['conv4'] = tf.Variable(weight_initializer([k, k, self.dim_hidden, self.dim_hidden]), name='conv4', dtype=dtype)\n","    weights['b4'] = tf.Variable(tf.zeros([self.dim_hidden]), name='b4')\n","    self.bn4 = tf.keras.layers.BatchNormalization(name='bn4')\n","    weights['w5'] = tf.Variable(weight_initializer(shape=[self.dim_hidden, self.dim_output]), name='w5', dtype=dtype)\n","    weights['b5'] = tf.Variable(tf.zeros([self.dim_output]), name='b5')\n","    self.conv_weights = weights\n","\n","  def call(self, inp, weights):\n","    channels = self.channels\n","    inp = tf.reshape(inp, [-1, self.img_size, self.img_size, channels])\n","    hidden1 = conv_block(inp, weights['conv1'], weights['b1'], self.bn1)\n","    hidden2 = conv_block(hidden1, weights['conv2'], weights['b2'], self.bn2)\n","    hidden3 = conv_block(hidden2, weights['conv3'], weights['b3'], self.bn3)\n","    hidden4 = conv_block(hidden3, weights['conv4'], weights['b4'], self.bn4)\n","    hidden4 = tf.reduce_mean(input_tensor=hidden4, axis=[1, 2])\n","    return tf.matmul(hidden4, weights['w5']) + weights['b5']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXZS_JULriBh"},"source":["\"\"\"Data loading scripts\"\"\"\n","## NOTE: You do not need to modify this block but you will need to use it.\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","from scipy import misc\n","import imageio\n","\n","def get_images(paths, labels, n_samples=None, shuffle=True):\n","  \"\"\"\n","  Takes a set of character folders and labels and returns paths to image files\n","  paired with labels.\n","  Args:\n","    paths: A list of character folders\n","    labels: List or numpy array of same length as paths\n","    n_samples: Number of images to retrieve per character\n","  Returns:\n","    List of (label, image_path) tuples\n","  \"\"\"\n","  if n_samples is not None:\n","    sampler = lambda x: random.sample(x, n_samples)\n","  else:\n","    sampler = lambda x: x\n","  images_labels = [(i, os.path.join(path, image))\n","           for i, path in zip(labels, paths)\n","           for image in sampler(os.listdir(path))]\n","  if shuffle:\n","    random.shuffle(images_labels)\n","  return images_labels\n","\n","\n","def image_file_to_array(filename, dim_input):\n","  \"\"\"\n","  Takes an image path and returns numpy array\n","  Args:\n","    filename: Image filename\n","    dim_input: Flattened shape of image\n","  Returns:\n","    1 channel image\n","  \"\"\"\n","  image = imageio.imread(filename)\n","  image = image.reshape([dim_input])\n","  image = image.astype(np.float32) / 255.0\n","  image = 1.0 - image\n","  return image\n","\n","\n","class DataGenerator(object):\n","  \"\"\"\n","  Data Generator capable of generating batches of Omniglot data.\n","  A \"class\" is considered a class of omniglot digits.\n","  \"\"\"\n","\n","  def __init__(self, num_classes, num_samples_per_class, num_meta_test_classes, num_meta_test_samples_per_class, config={}):\n","    \"\"\"\n","    Args:\n","      num_classes: Number of classes for classification (K-way)\n","      num_samples_per_class: num samples to generate per class in one batch\n","      num_meta_test_classes: Number of classes for classification (K-way) at meta-test time\n","      num_meta_test_samples_per_class: num samples to generate per class in one batch at meta-test time\n","      batch_size: size of meta batch size (e.g. number of functions)\n","    \"\"\"\n","    self.num_samples_per_class = num_samples_per_class\n","    self.num_classes = num_classes\n","    self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n","    self.num_meta_test_classes = num_meta_test_classes\n","\n","    data_folder = config.get('data_folder', './omniglot_resized')\n","    self.img_size = config.get('img_size', (28, 28))\n","\n","    self.dim_input = np.prod(self.img_size)\n","    self.dim_output = self.num_classes\n","\n","    character_folders = [os.path.join(data_folder, family, character)\n","               for family in os.listdir(data_folder)\n","               if os.path.isdir(os.path.join(data_folder, family))\n","               for character in os.listdir(os.path.join(data_folder, family))\n","               if os.path.isdir(os.path.join(data_folder, family, character))]\n","\n","    random.seed(123)\n","    random.shuffle(character_folders)\n","    num_val = 100\n","    num_train = 1100\n","    self.metatrain_character_folders = character_folders[: num_train]\n","    self.metaval_character_folders = character_folders[\n","      num_train:num_train + num_val]\n","    self.metatest_character_folders = character_folders[\n","      num_train + num_val:]\n","\n","  def sample_batch(self, batch_type, batch_size, shuffle=True, swap=False):\n","    \"\"\"\n","    Samples a batch for training, validation, or testing\n","    Args:\n","      batch_type: meta_train/meta_val/meta_test\n","      shuffle: randomly shuffle classes or not\n","      swap: swap number of classes (N) and number of samples per class (K) or not\n","    Returns:\n","      A a tuple of (1) Image batch and (2) Label batch where\n","      image batch has shape [B, N, K, 784] and label batch has shape [B, N, K, N] if swap is False\n","      where B is batch size, K is number of samples per class, N is number of classes\n","    \"\"\"\n","    if batch_type == \"meta_train\":\n","      folders = self.metatrain_character_folders\n","      num_classes = self.num_classes\n","      num_samples_per_class = self.num_samples_per_class\n","    elif batch_type == \"meta_val\":\n","      folders = self.metaval_character_folders\n","      num_classes = self.num_classes\n","      num_samples_per_class = self.num_samples_per_class\n","    else:\n","      folders = self.metatest_character_folders\n","      num_classes = self.num_meta_test_classes\n","      num_samples_per_class = self.num_meta_test_samples_per_class\n","    all_image_batches, all_label_batches = [], []\n","    for i in range(batch_size):\n","      sampled_character_folders = random.sample(\n","        folders, num_classes)\n","      labels_and_images = get_images(sampled_character_folders, range(\n","        num_classes), n_samples=num_samples_per_class, shuffle=False)\n","      labels = [li[0] for li in labels_and_images]\n","      images = [image_file_to_array(\n","        li[1], self.dim_input) for li in labels_and_images]\n","      images = np.stack(images)\n","      labels = np.array(labels).astype(np.int32)\n","      labels = np.reshape(\n","        labels, (num_classes, num_samples_per_class))\n","      labels = np.eye(num_classes, dtype=np.float32)[labels]\n","      images = np.reshape(\n","        images, (num_classes, num_samples_per_class, -1))\n","\n","      batch = np.concatenate([labels, images], 2)\n","      if shuffle:\n","        for p in range(num_samples_per_class):\n","          np.random.shuffle(batch[:, p])\n","\n","      labels = batch[:, :, :num_classes]\n","      images = batch[:, :, num_classes:]\n","\n","      if swap:\n","        labels = np.swapaxes(labels, 0, 1)\n","        images = np.swapaxes(images, 0, 1)\n","\n","      all_image_batches.append(images)\n","      all_label_batches.append(labels)\n","    all_image_batches = np.stack(all_image_batches)\n","    all_label_batches = np.stack(all_label_batches)\n","    return all_image_batches, all_label_batches"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxriXFvwsGfp"},"source":["\"\"\"MAML model code\"\"\"\n","import numpy as np\n","import sys\n","import tensorflow as tf\n","from functools import partial\n","\n","\n","class MAML(tf.keras.Model):\n","  def __init__(self, dim_input=1, dim_output=1,\n","               num_inner_updates=1,\n","               inner_update_lr=0.4, num_filters=32, k_shot=5, learn_inner_update_lr=False):\n","    super(MAML, self).__init__()\n","    self.dim_input = dim_input\n","    self.dim_output = dim_output\n","    self.inner_update_lr = inner_update_lr\n","    self.loss_func = partial(cross_entropy_loss, k_shot=k_shot)\n","    self.dim_hidden = num_filters\n","    self.channels = 1\n","    self.img_size = int(np.sqrt(self.dim_input/self.channels))\n","\n","    # outputs_ts[i] and losses_ts_post[i] are the output and loss after i+1 inner gradient updates\n","    losses_tr_pre, outputs_tr, losses_ts_post, outputs_ts = [], [], [], []\n","    accuracies_tr_pre, accuracies_ts = [], []\n","\n","    # for each loop in the inner training loop\n","    outputs_ts = [[]]*num_inner_updates\n","    losses_ts_post = [[]]*num_inner_updates\n","    accuracies_ts = [[]]*num_inner_updates\n","\n","    # Define the weights - these should NOT be directly modified by the\n","    # inner training loop\n","    tf.random.set_seed(seed)\n","    self.conv_layers = ConvLayers(self.channels, self.dim_hidden, self.dim_output, self.img_size)\n","\n","    self.learn_inner_update_lr = learn_inner_update_lr\n","    if self.learn_inner_update_lr:\n","      self.inner_update_lr_dict = {}\n","      for key in self.conv_layers.conv_weights.keys():\n","        self.inner_update_lr_dict[key] = [tf.Variable(self.inner_update_lr, name='inner_update_lr_%s_%d' % (key, j)) for j in range(num_inner_updates)]\n","  \n","\n","  def call(self, inp, meta_batch_size=25, num_inner_updates=1):\n","    def task_inner_loop(inp, reuse=True,\n","                      meta_batch_size=25, num_inner_updates=1):\n","      \"\"\"\n","        Perform gradient descent for one task in the meta-batch (i.e. inner-loop).\n","        Args:\n","          inp: a tuple (input_tr, input_ts, label_tr, label_ts), where input_tr and label_tr are the inputs and\n","            labels used for calculating inner loop gradients and input_ts and label_ts are the inputs and\n","            labels used for evaluating the model after inner updates.\n","            Should be shapes:\n","              input_tr: [N*K, 784]\n","              input_ts: [N*K, 784]\n","              label_tr: [N*K, N]\n","              label_ts: [N*K, N]\n","        Returns:\n","          task_output: a list of outputs, losses and accuracies at each inner update\n","      \"\"\"\n","      # the inner (input_tr, label_tr) and outer (input_ts, label_ts) loop data\n","      input_tr, input_ts, label_tr, label_ts = inp  # input: (N, K, 784), label: (N, K, N)\n","\n","      # weights corresponds to the initial weights in MAML (i.e. the meta-parameters)\n","      weights = self.conv_layers.conv_weights\n","\n","      # the predicted outputs, loss values, and accuracy for the pre-update model (with the initial weights)\n","      # evaluated on the inner loop training data\n","      task_output_tr_pre, task_loss_tr_pre, task_accuracy_tr_pre = None, None, None\n","\n","      # lists to keep track of outputs, losses, and accuracies of test data for each inner_update\n","      # where task_outputs_ts[i], task_losses_ts[i], task_accuracies_ts[i] are the output, loss, and accuracy\n","      # after i+1 inner gradient updates\n","      task_outputs_ts, task_losses_ts, task_accuracies_ts = [], [], []\n","  \n","      #############################\n","      #### YOUR CODE GOES HERE ####\n","      #### check (each example is a task? with N classes and K shot)\n","      ### is applied separately for example in batch using tf.map_fn\n","      N, K, _ = input_tr.shape  # (N, K, 784)\n","      label_tr = tf.reshape(label_tr, (N*K, -1))  # (N, K, N)  (-> (N*K, N)?)\n","      label_ts = tf.reshape(label_ts, (N*K, -1))  # (N, K, N)  (-> (N*K, N)?)\n","      dtype = tf.float32\n","      # create task-specific parameter \\theta_i^N, where \\theta_i^0 = \\theta\n","    #   modified_weights = {w_name: tf.Variable(w_val, name=w_name, dtype=dtype) for w_name, w_val in weights.items()}\n","      if self.learn_inner_update_lr:  # lr per-layer per-step\n","        # inner_update_lr_dict = {}\n","        # for key in modified_weights.keys():\n","        #   inner_update_lr_dict[key] = [tf.Variable(self.inner_update_lr_dict[key][iter], name='inner_update_lr_%s_%d' % (key, j)) for j in range(num_inner_updates)]\n","        for iter in range(num_inner_updates):\n","          with tf.GradientTape(persistent=True) as tape:\n","            task_output_tr_pre = self.conv_layers(input_tr, weights)  # predicted outputs  (modified_weights)\n","            task_loss_tr_pre = self.loss_func(task_output_tr_pre, label_tr)  #pred, label\n","        #   lr_params = [self.inner_update_lr_dict[key][iter] for key in weights.keys()]\n","        #   self.inner_update_lr_dict[key] = [tf.Variable(self.inner_update_lr, name='inner_update_lr_%s_%d' % (key, j)) for j in range(num_inner_updates)]\n","        #   gradients = tape.gradient(task_loss_tr_pre, modified_weights.values())\n","          gradients = tape.gradient(task_loss_tr_pre, weights.values())\n","        #   for i ,key in enumerate(modified_weights.keys()):\n","        #     # modified_weights[key] = modified_weights[key] - self.inner_update_lr_dict[key][iter] * gradients[i]  # per-layer per-step LR\n","        #     modified_weights[key].assign_sub(self.inner_update_lr_dict[key][iter] * gradients[i])  # option ii\n","\n","          for i ,key in enumerate(weights.keys()):\n","            # weights[key] = weights[key] - self.inner_update_lr_dict[key][iter] * gradients[i]  # per-layer per-step LR\n","\n","            weights[key].assign_sub(tf.math.multiply(self.inner_update_lr_dict[key][iter], gradients[i]))  # CHECK THIS!!!!!\n","            # weights[key].assign_sub(self.inner_update_lr_dict[key][iter] * gradients[i])  # option ii\n","\n","        #   task_output_ts = self.conv_layers(input_ts, modified_weights)\n","          task_output_ts = self.conv_layers(input_ts, weights)\n","          task_loss_ts = self.loss_func(task_output_ts, label_ts)\n","          task_outputs_ts.append(task_output_ts)\n","          task_losses_ts.append(task_loss_ts)\n","\n","        # if self.learn_inner_update_lr:  # lr per-layer per-step\n","        #     for i ,key in enumerate(weights.keys()):\n","        #       with tf.GradientTape(persistent=True) as lr_tape:\n","        #         f_lr = weights[key] - self.inner_update_lr_dict[key][iter] * gradients[i]  # should be of type EagerTensor\n","        #       lr_gradient = lr_tape.gradient(f_lr, self.inner_update_lr_dict[key][iter])\n","        #       weights[key].assign_sub(self.inner_update_lr_dict[key][iter] * gradients[i])\n","        #       self.inner_update_lr_dict[key][iter].assign_sub(self.inner_update_lr * lr_gradient)\n","            \n","      else:\n","        # modified_weights = {w_name: tf.Variable(w_val, name=w_name, dtype=dtype) for w_name, w_val in weights.items()}\n","        for iter in range(num_inner_updates):\n","          with tf.GradientTape(persistent=True) as tape:\n","            # task_output_tr_pre = self.conv_layers(input_tr, modified_weights)  # use modified_weights\n","            task_output_tr_pre = self.conv_layers(input_tr, weights)  # use weights\n","            task_loss_tr_pre = self.loss_func(task_output_tr_pre, label_tr)  #pred, label\n","        #   gradients = tape.gradient(task_loss_tr_pre, modified_weights.values())  # use modified_weights\n","          gradients = tape.gradient(task_loss_tr_pre, weights.values())  # use weights  \n","        #   for i, weight_name in enumerate(modified_weights.keys()):  \n","        #     modified_weights[weight_name] = modified_weights[weight_name] - (self.inner_update_lr * gradients[i])\n","        \n","        #   for i, weight_name in enumerate(modified_weights.keys()):  # modified weights\n","        #     modified_weights[weight_name].assign_sub(self.inner_update_lr * gradients[i])\n","\n","          for i, weight_name in enumerate(weights.keys()):  # weights\n","            weights[weight_name].assign_sub(self.inner_update_lr * gradients[i])\n","        #   modified_weights = ([weight - self.inner_update_lr * grad for weight, grad in zip(modified_weights.values(), gradients)])\n","          \n","        #   task_output_ts = self.conv_layers(input_ts, modified_weights)  # modified_weights\n","          task_output_ts = self.conv_layers(input_ts, weights)  # weights\n","          task_loss_ts = self.loss_func(task_output_ts, label_ts)\n","          task_outputs_ts.append(task_output_ts)\n","          task_losses_ts.append(task_loss_ts)\n","\n","      # perform num_inner_updates to get modified weights\n","      # modified weights should be used to evaluate performance\n","      # Note that at each inner update, always use input_tr and label_tr for calculating gradients\n","      # and use input_ts and labels for evaluating performance\n","\n","      # HINTS: You will need to use tf.GradientTape().\n","      # Read through the tf.GradientTape() documentation to see how 'persistent' should be set.\n","      # Here is some documentation that may be useful: \n","      # https://www.tensorflow.org/guide/advanced_autodiff#higher-order_gradients\n","      # https://www.tensorflow.org/api_docs/python/tf/GradientTape\n","\n","      \n","      #############################\n","\n","      # Compute accuracies from output predictions\n","      task_accuracy_tr_pre = accuracy(tf.argmax(input=label_tr, axis=1), tf.argmax(input=tf.nn.softmax(task_output_tr_pre), axis=1))\n","\n","      for j in range(num_inner_updates):\n","        task_accuracies_ts.append(accuracy(tf.argmax(input=label_ts, axis=1), tf.argmax(input=tf.nn.softmax(task_outputs_ts[j]), axis=1)))\n","\n","      task_output = [task_output_tr_pre, task_outputs_ts, task_loss_tr_pre, task_losses_ts, task_accuracy_tr_pre, task_accuracies_ts]\n","\n","      return task_output\n","\n","    input_tr, input_ts, label_tr, label_ts = inp\n","    # to initialize the batch norm vars, might want to combine this, and not run idx 0 twice.\n","    unused = task_inner_loop((input_tr[0], input_ts[0], label_tr[0], label_ts[0]),\n","                          False,\n","                          meta_batch_size,\n","                          num_inner_updates)\n","    out_dtype = [tf.float32, [tf.float32]*num_inner_updates, tf.float32, [tf.float32]*num_inner_updates]\n","    out_dtype.extend([tf.float32, [tf.float32]*num_inner_updates])\n","    task_inner_loop_partial = partial(task_inner_loop, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n","    result = tf.map_fn(task_inner_loop_partial,\n","                    elems=(input_tr, input_ts, label_tr, label_ts),\n","                    dtype=out_dtype,\n","                    parallel_iterations=meta_batch_size)\n","    return result\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xy1pz_ousUsz"},"source":["\"\"\"Model training code\"\"\"\n","\"\"\"\n","Usage Instructions:\n","  5-way, 1-shot omniglot:\n","    python main.py --meta_train_iterations=15000 --meta_batch_size=25 --k_shot=1 --inner_update_lr=0.4 --num_inner_updates=1 --logdir=logs/omniglot5way/\n","  20-way, 1-shot omniglot:\n","    python main.py --meta_train_iterations=15000 --meta_batch_size=16 --k_shot=1 --n_way=20 --inner_update_lr=0.1 --num_inner_updates=5 --logdir=logs/omniglot20way/\n","  To run evaluation, use the '--meta_train=False' flag and the '--meta_test_set=True' flag to use the meta-test set.\n","\"\"\"\n","import csv\n","import numpy as np\n","import pickle\n","import random\n","import tensorflow as tf\n","\n","def outer_train_step(inp, model, optim, meta_batch_size=25, num_inner_updates=1):\n","  with tf.GradientTape(persistent=False) as outer_tape:\n","    result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n","\n","    outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n","\n","    total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n","  gradients = outer_tape.gradient(total_losses_ts[-1], model.trainable_variables)\n","  optim.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n","  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n","  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n","\n","  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts\n","\n","def outer_eval_step(inp, model, meta_batch_size=25, num_inner_updates=1):\n","  result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n","\n","  outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n","\n","  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n","  total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n","\n","  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n","  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n","\n","  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts  \n","\n","\n","def meta_train_fn(model, exp_string, data_generator,\n","               n_way=5, meta_train_iterations=15000, meta_batch_size=25,\n","               log=True, logdir='/tmp/data', k_shot=1, num_inner_updates=1, meta_lr=0.001):\n","  # originally meta_train_iterations=15000\n","  SUMMARY_INTERVAL = 10\n","  SAVE_INTERVAL = 100\n","  PRINT_INTERVAL = 10  \n","  TEST_PRINT_INTERVAL = PRINT_INTERVAL*5\n","\n","  pre_accuracies, post_accuracies = [], []\n","\n","  num_classes = data_generator.num_classes\n","\n","  optimizer = tf.keras.optimizers.Adam(learning_rate=meta_lr)\n","\n","  for itr in range(meta_train_iterations):\n","    #############################\n","    #### YOUR CODE GOES HERE ####\n","\n","    # call data_generator and get data with k_shot*2 samples per class\n","\n","    inputs, labels = data_generator.sample_batch('meta_train', meta_batch_size)  # [B, N, 2* K, 784]  [B, N, 2 * K , N]\n","    K_tr = int(data_generator.num_samples_per_class / 2)\n","    input_tr = inputs[:, :, :K_tr, :]  # [B, N, K_tr, 784]\n","    label_tr = labels[:, :, :K_tr, :]  # [B, N, K_tr , N]\n","    input_ts = inputs[:, :, K_tr:, :]  # [B, N, K_tr, 784]\n","    label_ts = labels[:, :, K_tr:, :]  # [B, N, K_tr , N]\n","    # sample a batch of training data and partition into\n","    # the support/training set (input_tr, label_tr) and the query/test set (input_ts, label_ts)\n","    # NOTE: The code assumes that the support and query sets have the same number of examples.\n","\n","    #############################\n","\n","    inp = (input_tr, input_ts, label_tr, label_ts)\n","    \n","    result = outer_train_step(inp, model, optimizer, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n","\n","    if itr % SUMMARY_INTERVAL == 0:\n","      pre_accuracies.append(result[-2])\n","      post_accuracies.append(result[-1][-1])\n","\n","    if (itr!=0) and itr % PRINT_INTERVAL == 0:\n","      print_str = 'Iteration %d: pre-inner-loop train accuracy: %.5f, post-inner-loop test accuracy: %.5f' % (itr, np.mean(pre_accuracies), np.mean(post_accuracies))\n","      print(print_str)\n","      pre_accuracies, post_accuracies = [], []\n","\n","    if (itr!=0) and itr % TEST_PRINT_INTERVAL == 0:\n","      #############################\n","      #### YOUR CODE GOES HERE ####\n","      inputs, labels = data_generator.sample_batch('meta_val', meta_batch_size)  # [B, N, 2* K, 784]  [B, N, 2 * K , N]\n","      K_val = int(data_generator.num_samples_per_class / 2)\n","      input_tr = inputs[:, :, :K_val, :]  # [B, N, K_tr, 784]\n","      label_tr = labels[:, :, :K_val, :]  # [B, N, K_tr , N]\n","      input_ts = inputs[:, :, K_val:, :]  # [B, N, K_tr, 784]\n","      label_ts = labels[:, :, K_val:, :]  # [B, N, K_tr , N]\n","      # sample a batch of validation data and partition it into\n","      # the support/training set (input_tr, label_tr) and the query/test set (input_ts, label_ts)\n","      # NOTE: The code assumes that the support and query sets have the same number of examples.\n","\n","      #############################\n","\n","      inp = (input_tr, input_ts, label_tr, label_ts)\n","      result = outer_eval_step(inp, model, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n","\n","      print('Meta-validation pre-inner-loop train accuracy: %.5f, meta-validation post-inner-loop test accuracy: %.5f' % (result[-2], result[-1][-1]))\n","\n","  model_file = logdir + '/' + exp_string +  '/model' + str(itr)\n","  print(\"Saving to \", model_file)\n","  model.save_weights(model_file)\n","\n","# calculated for omniglot\n","NUM_META_TEST_POINTS = 600\n","\n","def meta_test_fn(model, data_generator, n_way=5, meta_batch_size=25, k_shot=1,\n","              num_inner_updates=1):\n","  \n","  num_classes = data_generator.num_classes\n","\n","  np.random.seed(1)\n","  random.seed(1)\n","\n","  meta_test_accuracies = []\n","\n","  for _ in range(NUM_META_TEST_POINTS):\n","    #############################\n","    #### YOUR CODE GOES HERE ####\n","    inputs, labels = data_generator.sample_batch('meta_test', meta_batch_size)  # [B, N, 2* K, 784]  [B, N, 2 * K , N]\n","    K_ts = int(data_generator.num_meta_test_samples_per_class / 2)\n","    input_tr = inputs[:, :, :K_ts, :]  # [B, N, K_ts, 784]\n","    label_tr = labels[:, :, :K_ts, :]  # [B, N, K_ts , N]\n","    input_ts = inputs[:, :, K_ts:, :]  # [B, N, K_ts, 784]\n","    label_ts = labels[:, :, K_ts:, :]  # [B, N, K_ts , N]\n","    # sample a batch of test data and partition it into\n","    # the support/training set (input_tr, label_tr) and the query/test set (input_ts, label_ts)\n","    # NOTE: The code assumes that the support and query sets have the same number of examples.\n","    \n","    #############################\n","    inp = (input_tr, input_ts, label_tr, label_ts)\n","    result = outer_eval_step(inp, model, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n","\n","    meta_test_accuracies.append(result[-1][-1])\n","\n","  meta_test_accuracies = np.array(meta_test_accuracies)\n","  means = np.mean(meta_test_accuracies)\n","  stds = np.std(meta_test_accuracies)\n","  ci95 = 1.96*stds/np.sqrt(NUM_META_TEST_POINTS)\n","\n","  print('Mean meta-test accuracy/loss, stddev, and confidence intervals')\n","  print((means, stds, ci95))\n","\n","\n","def run_maml(n_way=5, k_shot=1, meta_batch_size=25, meta_lr=0.001,\n","             inner_update_lr=0.4, num_filters=32, num_inner_updates=1,\n","             learn_inner_update_lr=False,\n","             resume=False, resume_itr=0, log=True, logdir='/tmp/data',\n","             data_path='./omniglot_resized',meta_train=True,\n","             meta_train_iterations=1500, meta_train_k_shot=-1,\n","             meta_train_inner_update_lr=-1):\n","\n","  # origianlly meta_train_iterations=15000\n","  # call data_generator and get data with k_shot*2 samples per class\n","  data_generator = DataGenerator(n_way, k_shot*2, n_way, k_shot*2, config={'data_folder': data_path})\n","\n","  # set up MAML model\n","  dim_output = data_generator.dim_output\n","  dim_input = data_generator.dim_input\n","  model = MAML(dim_input,\n","              dim_output,\n","              num_inner_updates=num_inner_updates,\n","              inner_update_lr=inner_update_lr,\n","              k_shot=k_shot,\n","              num_filters=num_filters,\n","              learn_inner_update_lr=learn_inner_update_lr)\n","\n","  if meta_train_k_shot == -1:\n","    meta_train_k_shot = k_shot\n","  if meta_train_inner_update_lr == -1:\n","    meta_train_inner_update_lr = inner_update_lr\n","\n","  exp_string = 'cls_'+str(n_way)+'.mbs_'+str(meta_batch_size) + '.k_shot_' + str(meta_train_k_shot) + '.inner_numstep_' + str(num_inner_updates) + '.inner_updatelr_' + str(meta_train_inner_update_lr) + '.learn_inner_update_lr_' + str(learn_inner_update_lr)\n","\n","\n","  if meta_train:\n","    meta_train_fn(model, exp_string, data_generator,\n","                  n_way, meta_train_iterations, meta_batch_size, log, logdir,\n","                  k_shot, num_inner_updates, meta_lr)\n","  else:\n","    meta_batch_size = 1\n","\n","    model_file = tf.train.latest_checkpoint(logdir + '/' + exp_string)\n","    print(\"Restoring model weights from \", model_file)\n","    model.load_weights(model_file)\n","\n","    meta_test_fn(model, data_generator, n_way, meta_batch_size, k_shot, num_inner_updates)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"USOh7VulTMK3","colab":{"base_uri":"https://localhost:8080/","height":403},"executionInfo":{"status":"error","timestamp":1632647948851,"user_tz":-180,"elapsed":6470,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"69e34223-641c-43d2-f671-c7140fafede8"},"source":["# lr: 0.4 (1500 iterations): post inner loop train: 0.472, post inner loop validation ~0.456\n","run_maml(n_way=5, k_shot=1, inner_update_lr=0.4, num_inner_updates=1)\n","# run_maml(n_way=5, k_shot=1, inner_update_lr=0.04, num_inner_updates=1)\n","# run_maml(n_way=5, k_shot=1, inner_update_lr=4.0, num_inner_updates=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['b1:0', 'b2:0', 'b3:0', 'b4:0', 'b5:0', 'conv1:0', 'conv2:0', 'conv3:0', 'conv4:0', 'w5:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['b1:0', 'b2:0', 'b3:0', 'b4:0', 'b5:0', 'conv1:0', 'conv2:0', 'conv3:0', 'conv4:0', 'w5:0'] when minimizing the loss.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-441cf359b081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lr: 0.4 (1500 iterations): post inner loop train: 0.472, post inner loop validation ~0.456\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_maml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# run_maml(n_way=5, k_shot=1, inner_update_lr=0.04, num_inner_updates=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# run_maml(n_way=5, k_shot=1, inner_update_lr=4.0, num_inner_updates=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mrun_maml\u001b[0;34m(n_way, k_shot, meta_batch_size, meta_lr, inner_update_lr, num_filters, num_inner_updates, learn_inner_update_lr, resume, resume_itr, log, logdir, data_path, meta_train, meta_train_iterations, meta_train_k_shot, meta_train_inner_update_lr)\u001b[0m\n\u001b[1;32m    189\u001b[0m     meta_train_fn(model, exp_string, data_generator,\n\u001b[1;32m    190\u001b[0m                   \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_train_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                   k_shot, num_inner_updates, meta_lr)\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mmeta_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mmeta_train_fn\u001b[0;34m(model, exp_string, data_generator, n_way, meta_train_iterations, meta_batch_size, log, logdir, k_shot, num_inner_updates, meta_lr)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSUMMARY_INTERVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mouter_train_step\u001b[0;34m(inp, model, optim, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mouter_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moutputs_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_tr_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_tr_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-1baf2f12448c>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m    161\u001b[0m                     \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                     parallel_iterations=meta_batch_size)\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn_v2\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0minfer_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0mresult_batchable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2766\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2767\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2768\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2769\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0mag_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m       \u001b[0mautographed_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m       \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautographed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_output_signature\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0mresult_value_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         options=options)\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmpb_ake9pz.py\u001b[0m in \u001b[0;36mtf__task_inner_loop\u001b[0;34m(inp, reuse, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_inner_update_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'task_loss_tr_pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'task_output_tr_pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mtask_output_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mtask_loss_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_output_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_outputs_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_output_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_losses_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_loss_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         options=options)\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmp1ih4v2yz.py\u001b[0m in \u001b[0;36mtf__cross_entropy_loss\u001b[0;34m(pred, label, k_shot)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_shot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, axis, name)\u001b[0m\n\u001b[1;32m   3962\u001b[0m   \"\"\"\n\u001b[1;32m   3963\u001b[0m   return softmax_cross_entropy_with_logits_v2_helper(\n\u001b[0;32m-> 3964\u001b[0;31m       labels=labels, logits=logits, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits_v2_helper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4036\u001b[0m     \u001b[0;31m# labels and logits must be of the same type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4037\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4038\u001b[0;31m     \u001b[0minput_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecise_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4039\u001b[0m     \u001b[0;31m# For shape inference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4040\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    837\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m   \"\"\"\n\u001b[0;32m--> 839\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[0;34m(input, name, optimize)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bBzmv9oVqDq","executionInfo":{"status":"ok","timestamp":1632652091975,"user_tz":-180,"elapsed":3645011,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"2f670a14-86c1-42cb-87a9-01b3b6a78d33"},"source":["# if works, check num_inner_updates > 1\n","run_maml(n_way=5, k_shot=1, inner_update_lr=0.4, num_inner_updates=2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 10: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.21600\n","Iteration 20: pre-inner-loop train accuracy: 0.25600, post-inner-loop test accuracy: 0.22400\n","Iteration 30: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.23200\n","Iteration 40: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20800\n","Iteration 50: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.19200, meta-validation post-inner-loop test accuracy: 0.12800\n","Iteration 60: pre-inner-loop train accuracy: 0.24000, post-inner-loop test accuracy: 0.19200\n","Iteration 70: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.20800\n","Iteration 80: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.23200\n","Iteration 90: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.13600\n","Iteration 100: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.19200\n","Meta-validation pre-inner-loop train accuracy: 0.17600, meta-validation post-inner-loop test accuracy: 0.21600\n","Iteration 110: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.14400\n","Iteration 120: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.23200\n","Iteration 130: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.17600\n","Iteration 140: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.22400\n","Iteration 150: pre-inner-loop train accuracy: 0.25600, post-inner-loop test accuracy: 0.24800\n","Meta-validation pre-inner-loop train accuracy: 0.21600, meta-validation post-inner-loop test accuracy: 0.20800\n","Iteration 160: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.20800\n","Iteration 170: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.20800\n","Iteration 180: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.16800\n","Iteration 190: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.14400\n","Iteration 200: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.20800\n","Meta-validation pre-inner-loop train accuracy: 0.16800, meta-validation post-inner-loop test accuracy: 0.16800\n","Iteration 210: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20800\n","Iteration 220: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.17600\n","Iteration 230: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.14400\n","Iteration 240: pre-inner-loop train accuracy: 0.15200, post-inner-loop test accuracy: 0.21600\n","Iteration 250: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.19200\n","Meta-validation pre-inner-loop train accuracy: 0.20000, meta-validation post-inner-loop test accuracy: 0.21600\n","Iteration 260: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.17600\n","Iteration 270: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.19200\n","Iteration 280: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.21600\n","Iteration 290: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.23200\n","Iteration 300: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.16800\n","Meta-validation pre-inner-loop train accuracy: 0.21600, meta-validation post-inner-loop test accuracy: 0.20800\n","Iteration 310: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20800\n","Iteration 320: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.16800\n","Iteration 330: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.18400\n","Iteration 340: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.13600\n","Iteration 350: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.16000\n","Meta-validation pre-inner-loop train accuracy: 0.22400, meta-validation post-inner-loop test accuracy: 0.18400\n","Iteration 360: pre-inner-loop train accuracy: 0.23200, post-inner-loop test accuracy: 0.21600\n","Iteration 370: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.23200\n","Iteration 380: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.20800\n","Iteration 390: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.16800\n","Iteration 400: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.20000\n","Meta-validation pre-inner-loop train accuracy: 0.19200, meta-validation post-inner-loop test accuracy: 0.20000\n","Iteration 410: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.18400\n","Iteration 420: pre-inner-loop train accuracy: 0.23200, post-inner-loop test accuracy: 0.17600\n","Iteration 430: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.15200\n","Iteration 440: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.18400\n","Iteration 450: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.17600, meta-validation post-inner-loop test accuracy: 0.16000\n","Iteration 460: pre-inner-loop train accuracy: 0.16000, post-inner-loop test accuracy: 0.22400\n","Iteration 470: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.21600\n","Iteration 480: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.16000\n","Iteration 490: pre-inner-loop train accuracy: 0.24800, post-inner-loop test accuracy: 0.18400\n","Iteration 500: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.21600\n","Meta-validation pre-inner-loop train accuracy: 0.20000, meta-validation post-inner-loop test accuracy: 0.22400\n","Iteration 510: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.16000\n","Iteration 520: pre-inner-loop train accuracy: 0.24800, post-inner-loop test accuracy: 0.23200\n","Iteration 530: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.18400\n","Iteration 540: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.20800\n","Iteration 550: pre-inner-loop train accuracy: 0.15200, post-inner-loop test accuracy: 0.16000\n","Meta-validation pre-inner-loop train accuracy: 0.16000, meta-validation post-inner-loop test accuracy: 0.19200\n","Iteration 560: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.25600\n","Iteration 570: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.19200\n","Iteration 580: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.18400\n","Iteration 590: pre-inner-loop train accuracy: 0.13600, post-inner-loop test accuracy: 0.19200\n","Iteration 600: pre-inner-loop train accuracy: 0.14400, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.17600, meta-validation post-inner-loop test accuracy: 0.16000\n","Iteration 610: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.16000\n","Iteration 620: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.19200\n","Iteration 630: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.16800\n","Iteration 640: pre-inner-loop train accuracy: 0.16000, post-inner-loop test accuracy: 0.17600\n","Iteration 650: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.19200\n","Meta-validation pre-inner-loop train accuracy: 0.19200, meta-validation post-inner-loop test accuracy: 0.16800\n","Iteration 660: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.19200\n","Iteration 670: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.21600\n","Iteration 680: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.20800\n","Iteration 690: pre-inner-loop train accuracy: 0.14400, post-inner-loop test accuracy: 0.15200\n","Iteration 700: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20800\n","Meta-validation pre-inner-loop train accuracy: 0.16800, meta-validation post-inner-loop test accuracy: 0.15200\n","Iteration 710: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.20800\n","Iteration 720: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.16000\n","Iteration 730: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.17600\n","Iteration 740: pre-inner-loop train accuracy: 0.15200, post-inner-loop test accuracy: 0.16800\n","Iteration 750: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.20000\n","Meta-validation pre-inner-loop train accuracy: 0.24800, meta-validation post-inner-loop test accuracy: 0.21600\n","Iteration 760: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.21600\n","Iteration 770: pre-inner-loop train accuracy: 0.25600, post-inner-loop test accuracy: 0.22400\n","Iteration 780: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.19200\n","Iteration 790: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.19200\n","Iteration 800: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.20000\n","Meta-validation pre-inner-loop train accuracy: 0.24000, meta-validation post-inner-loop test accuracy: 0.18400\n","Iteration 810: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20000\n","Iteration 820: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.19200\n","Iteration 830: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.20000\n","Iteration 840: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.17600\n","Iteration 850: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.24000, meta-validation post-inner-loop test accuracy: 0.24800\n","Iteration 860: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.20000\n","Iteration 870: pre-inner-loop train accuracy: 0.15200, post-inner-loop test accuracy: 0.18400\n","Iteration 880: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.14400\n","Iteration 890: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.24000\n","Iteration 900: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.18400\n","Meta-validation pre-inner-loop train accuracy: 0.21600, meta-validation post-inner-loop test accuracy: 0.24000\n","Iteration 910: pre-inner-loop train accuracy: 0.23200, post-inner-loop test accuracy: 0.23200\n","Iteration 920: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20800\n","Iteration 930: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.14400\n","Iteration 940: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.12800\n","Iteration 950: pre-inner-loop train accuracy: 0.23200, post-inner-loop test accuracy: 0.19200\n","Meta-validation pre-inner-loop train accuracy: 0.18400, meta-validation post-inner-loop test accuracy: 0.14400\n","Iteration 960: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.18400\n","Iteration 970: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.17600\n","Iteration 980: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20000\n","Iteration 990: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.20800\n","Iteration 1000: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.20000\n","Meta-validation pre-inner-loop train accuracy: 0.23200, meta-validation post-inner-loop test accuracy: 0.20000\n","Iteration 1010: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.16000\n","Iteration 1020: pre-inner-loop train accuracy: 0.16000, post-inner-loop test accuracy: 0.13600\n","Iteration 1030: pre-inner-loop train accuracy: 0.24000, post-inner-loop test accuracy: 0.24000\n","Iteration 1040: pre-inner-loop train accuracy: 0.16000, post-inner-loop test accuracy: 0.18400\n","Iteration 1050: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.22400\n","Meta-validation pre-inner-loop train accuracy: 0.23200, meta-validation post-inner-loop test accuracy: 0.16800\n","Iteration 1060: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.24800\n","Iteration 1070: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.16000\n","Iteration 1080: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.14400\n","Iteration 1090: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.20800\n","Iteration 1100: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.20800, meta-validation post-inner-loop test accuracy: 0.21600\n","Iteration 1110: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.23200\n","Iteration 1120: pre-inner-loop train accuracy: 0.16000, post-inner-loop test accuracy: 0.15200\n","Iteration 1130: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.17600\n","Iteration 1140: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.22400\n","Iteration 1150: pre-inner-loop train accuracy: 0.15200, post-inner-loop test accuracy: 0.13600\n","Meta-validation pre-inner-loop train accuracy: 0.17600, meta-validation post-inner-loop test accuracy: 0.22400\n","Iteration 1160: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.20800\n","Iteration 1170: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.17600\n","Iteration 1180: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.20800\n","Iteration 1190: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.20000\n","Iteration 1200: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.21600, meta-validation post-inner-loop test accuracy: 0.21600\n","Iteration 1210: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20000\n","Iteration 1220: pre-inner-loop train accuracy: 0.12000, post-inner-loop test accuracy: 0.15200\n","Iteration 1230: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.22400\n","Iteration 1240: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.24000\n","Iteration 1250: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.23200\n","Meta-validation pre-inner-loop train accuracy: 0.23200, meta-validation post-inner-loop test accuracy: 0.20800\n","Iteration 1260: pre-inner-loop train accuracy: 0.27200, post-inner-loop test accuracy: 0.22400\n","Iteration 1270: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.16800\n","Iteration 1280: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.22400\n","Iteration 1290: pre-inner-loop train accuracy: 0.16000, post-inner-loop test accuracy: 0.19200\n","Iteration 1300: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.19200\n","Meta-validation pre-inner-loop train accuracy: 0.19200, meta-validation post-inner-loop test accuracy: 0.20800\n","Iteration 1310: pre-inner-loop train accuracy: 0.21600, post-inner-loop test accuracy: 0.16800\n","Iteration 1320: pre-inner-loop train accuracy: 0.24800, post-inner-loop test accuracy: 0.17600\n","Iteration 1330: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.14400\n","Iteration 1340: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.17600\n","Iteration 1350: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.24000\n","Meta-validation pre-inner-loop train accuracy: 0.21600, meta-validation post-inner-loop test accuracy: 0.20800\n","Iteration 1360: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.22400\n","Iteration 1370: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.20800\n","Iteration 1380: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.21600\n","Iteration 1390: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.15200\n","Iteration 1400: pre-inner-loop train accuracy: 0.24000, post-inner-loop test accuracy: 0.23200\n","Meta-validation pre-inner-loop train accuracy: 0.24800, meta-validation post-inner-loop test accuracy: 0.22400\n","Iteration 1410: pre-inner-loop train accuracy: 0.23200, post-inner-loop test accuracy: 0.22400\n","Iteration 1420: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.19200\n","Iteration 1430: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.22400\n","Iteration 1440: pre-inner-loop train accuracy: 0.23200, post-inner-loop test accuracy: 0.22400\n","Iteration 1450: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20800\n","Meta-validation pre-inner-loop train accuracy: 0.16000, meta-validation post-inner-loop test accuracy: 0.14400\n","Iteration 1460: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.20000\n","Iteration 1470: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.16800\n","Iteration 1480: pre-inner-loop train accuracy: 0.13600, post-inner-loop test accuracy: 0.18400\n","Iteration 1490: pre-inner-loop train accuracy: 0.22400, post-inner-loop test accuracy: 0.20800\n","Saving to  /tmp/data/cls_5.mbs_25.k_shot_1.inner_numstep_2.inner_updatelr_0.4.learn_inner_update_lr_False/model1499\n"]}]},{"cell_type":"code","metadata":{"id":"-d3YbJzqm8MX","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1632652652627,"user_tz":-180,"elapsed":21889,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"0b8761bc-eb90-41ae-df25-b87f48836089"},"source":["# lr (learn_inner_update_lr=True): 0.4 (1500 iterations): post inner loop train: 0.472, post inner loop validation ~0.456\n","run_maml(n_way=5, k_shot=1, inner_update_lr=0.4, num_inner_updates=1, learn_inner_update_lr=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424790>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424b10>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424650>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe3794240d0>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424190>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424750>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424450>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe378e9ce90>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","ERROR:tensorflow:==================================\n","Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n","<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe379424c10>\n","If you want to mark it as used call its \"mark_used()\" method.\n","It was originally created here:\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2820, in while_loop\n","    return result  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2768, in <lambda>\n","    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 499, in compute\n","    return (i + 1, tas)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\", line 497, in <listcomp>\n","    ta.write(i, value) for (ta, value) in zip(tas, result_value_batchable)  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n","    error_in_function=error_in_function)\n","==================================\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","Iteration 10: pre-inner-loop train accuracy: 0.18400, post-inner-loop test accuracy: 0.20000\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_w5_0:0'] when minimizing the loss.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-3fc86db6b353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lr (learn_inner_update_lr=True): 0.4 (1500 iterations): post inner loop train: 0.472, post inner loop validation ~0.456\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_maml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_inner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mrun_maml\u001b[0;34m(n_way, k_shot, meta_batch_size, meta_lr, inner_update_lr, num_filters, num_inner_updates, learn_inner_update_lr, resume, resume_itr, log, logdir, data_path, meta_train, meta_train_iterations, meta_train_k_shot, meta_train_inner_update_lr)\u001b[0m\n\u001b[1;32m    189\u001b[0m     meta_train_fn(model, exp_string, data_generator,\n\u001b[1;32m    190\u001b[0m                   \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_train_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                   k_shot, num_inner_updates, meta_lr)\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mmeta_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mmeta_train_fn\u001b[0;34m(model, exp_string, data_generator, n_way, meta_train_iterations, meta_batch_size, log, logdir, k_shot, num_inner_updates, meta_lr)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSUMMARY_INTERVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mouter_train_step\u001b[0;34m(inp, model, optim, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mouter_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moutputs_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_tr_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_tr_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-9cddcfd5ba5b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     parallel_iterations=meta_batch_size)\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn_v2\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0minfer_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0mresult_batchable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2766\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2767\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2768\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2769\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0mag_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m       \u001b[0mautographed_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m       \u001b[0mresult_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautographed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_output_signature\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0mresult_value_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         options=options)\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmp4_ogcf9p.py\u001b[0m in \u001b[0;36mtf__task_inner_loop\u001b[0;34m(inp, reuse, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_inner_update_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'task_loss_tr_pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'task_output_tr_pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0mtask_accuracy_tr_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_output_tr_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;3...\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0m_tf_if_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m     \u001b[0m_py_if_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_py_if_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m   \u001b[0;34m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0morelse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/tmp4_ogcf9p.py\u001b[0m in \u001b[0;36mif_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'task_loss_tr_pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'task_output_tr_pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'iterate_names'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'iter'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[0;34m(protected_iter)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0moriginal_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/tmp4_ogcf9p.py\u001b[0m in \u001b[0;36mloop_body_1\u001b[0;34m(itr_1)\u001b[0m\n\u001b[1;32m     42\u001b[0m                             \u001b[0mtask_output_tr_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                             \u001b[0mtask_loss_tr_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_output_tr_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_loss_tr_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0mflat_sources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_handle_or_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_sources\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         logging.vlog(\n\u001b[1;32m   1072\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The dtype of the source tensor must be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop_util.py\u001b[0m in \u001b[0;36mIsTrainable\u001b[0;34m(tensor_or_dtype)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;34m\"\"\"Determines whether a tensor or dtype supports infinitesimal changes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tf_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DTypeFromTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_or_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop_util.py\u001b[0m in \u001b[0;36m_DTypeFromTensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;34m\"\"\"Extract either `tensor.dtype` or the unanimous sub-type of a variant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# If we know statically that the data a variant points to is non-trainable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# then the variant itself is non-trainable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xoKSAvpSVwe2","executionInfo":{"status":"error","timestamp":1632652860059,"user_tz":-180,"elapsed":203361,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"ec832e5f-0189-4534-95c9-15159477da1e"},"source":["# lr (learn_inner_update_lr=True): 0.4 (1500 iterations): (check num_inner_updates > 1)\n","run_maml(n_way=5, k_shot=1, inner_update_lr=0.4, num_inner_updates=2, learn_inner_update_lr=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 10: pre-inner-loop train accuracy: 0.24000, post-inner-loop test accuracy: 0.23200\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 20: pre-inner-loop train accuracy: 0.19200, post-inner-loop test accuracy: 0.16800\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 30: pre-inner-loop train accuracy: 0.24000, post-inner-loop test accuracy: 0.20800\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 40: pre-inner-loop train accuracy: 0.20000, post-inner-loop test accuracy: 0.20000\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 50: pre-inner-loop train accuracy: 0.16800, post-inner-loop test accuracy: 0.17600\n","Meta-validation pre-inner-loop train accuracy: 0.24000, meta-validation post-inner-loop test accuracy: 0.21600\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 60: pre-inner-loop train accuracy: 0.17600, post-inner-loop test accuracy: 0.18400\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 70: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.16000\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","Iteration 80: pre-inner-loop train accuracy: 0.20800, post-inner-loop test accuracy: 0.18400\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['inner_update_lr_b1_0:0', 'inner_update_lr_b1_1:0', 'inner_update_lr_b2_0:0', 'inner_update_lr_b2_1:0', 'inner_update_lr_b3_0:0', 'inner_update_lr_b3_1:0', 'inner_update_lr_b4_0:0', 'inner_update_lr_b4_1:0', 'inner_update_lr_b5_0:0', 'inner_update_lr_b5_1:0', 'inner_update_lr_conv1_0:0', 'inner_update_lr_conv1_1:0', 'inner_update_lr_conv2_0:0', 'inner_update_lr_conv2_1:0', 'inner_update_lr_conv3_0:0', 'inner_update_lr_conv3_1:0', 'inner_update_lr_conv4_0:0', 'inner_update_lr_conv4_1:0', 'inner_update_lr_w5_0:0', 'inner_update_lr_w5_1:0'] when minimizing the loss.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-0fbcb82b0d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lr (learn_inner_update_lr=True): 0.4 (1500 iterations): (check num_inner_updates > 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_maml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_inner_update_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mrun_maml\u001b[0;34m(n_way, k_shot, meta_batch_size, meta_lr, inner_update_lr, num_filters, num_inner_updates, learn_inner_update_lr, resume, resume_itr, log, logdir, data_path, meta_train, meta_train_iterations, meta_train_k_shot, meta_train_inner_update_lr)\u001b[0m\n\u001b[1;32m    189\u001b[0m     meta_train_fn(model, exp_string, data_generator,\n\u001b[1;32m    190\u001b[0m                   \u001b[0mn_way\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_train_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                   k_shot, num_inner_updates, meta_lr)\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mmeta_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mmeta_train_fn\u001b[0;34m(model, exp_string, data_generator, n_way, meta_train_iterations, meta_batch_size, log, logdir, k_shot, num_inner_updates, meta_lr)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSUMMARY_INTERVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-1cbea9ab4cde>\u001b[0m in \u001b[0;36mouter_train_step\u001b[0;34m(inp, model, optim, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mouter_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moutputs_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_tr_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_tr_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-9cddcfd5ba5b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     parallel_iterations=meta_batch_size)\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn_v2\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    649\u001b[0m       \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m       \u001b[0minfer_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 instructions)\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0mresult_batchable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2774\u001b[0m       loop_var_structure = nest.map_structure(type_spec.type_spec_from_value,\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[0;32m-> 2776\u001b[0;31m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2765\u001b[0m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m-> 2767\u001b[0;31m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0m\u001b[1;32m   2768\u001b[0m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mlogical_and\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5404\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 5405\u001b[0;31m         _ctx, \"LogicalAnd\", name, x, y)\n\u001b[0m\u001b[1;32m   5406\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5407\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ohmGfgV-geFj"},"source":["# models/ProtoNet\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","class ProtoNet(tf.keras.Model):\n","\n","  def __init__(self, num_filters, latent_dim):\n","    super(ProtoNet, self).__init__()\n","    self.num_filters = num_filters\n","    self.latent_dim = latent_dim\n","    num_filter_list = self.num_filters + [latent_dim]\n","    self.convs = []\n","    for i, num_filter in enumerate(num_filter_list):\n","      block_parts = [\n","        layers.Conv2D(\n","          filters=num_filter,\n","          kernel_size=3,\n","          padding='SAME',\n","          activation='linear'),\n","      ]\n","\n","      block_parts += [layers.BatchNormalization()]\n","      block_parts += [layers.Activation('relu')]\n","      block_parts += [layers.MaxPool2D()]\n","      block = tf.keras.Sequential(block_parts, name='conv_block_%d' % i)\n","      self.__setattr__(\"conv%d\" % i, block)\n","      self.convs.append(block)\n","    self.flatten = tf.keras.layers.Flatten()\n","\n","  def call(self, inp):\n","    out = inp\n","    for conv in self.convs:\n","      out = conv(out)\n","    out = self.flatten(out)\n","    return out\n","\n","def ProtoLoss(x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries, test=False):\n","  \"\"\"\n","    calculates the prototype network loss using the latent representation of x\n","    and the latent representation of the query set\n","    Args:\n","      x_latent: latent representation of supports with shape [N*S, D], where D is the latent dimension\n","      q_latent: latent representation of queries with shape [N*Q, D], where D is the latent dimension\n","      labels_onehot: one-hot encodings of the labels of the queries with shape [N, Q, N]\n","      num_classes: number of classes (N) for classification\n","      num_support: number of examples (S) in the support set\n","      num_queries: number of examples (Q) in the query set\n","    Returns:\n","      ce_loss: the cross entropy loss between the predicted labels and true labels\n","      acc: the accuracy of classification on the queries\n","  \"\"\"\n","  #############################\n","  #### YOUR CODE GOES HERE ####\n","  x_latent = tf.linalg.l2_normalize(x_latent, axis=1)  # normalize x_latent (l2 norm)\n","  q_latent = tf.linalg.l2_normalize(q_latent, axis=1)  # normalize q_latent (l2 norm)\n","#   x_latent = tf.linalg.normalize(x_latent, axis=1, ord=1)[0]  # normalize x_latent (l1 norm)\n","#   q_latent = tf.linalg.normalize(q_latent, axis=1, ord=1)[0]  # normalize q_latent (l1 norm)\n","  x_latent = tf.reshape(x_latent, (num_classes, num_support, -1))  # (N, S, D)\n","  q_latent = tf.reshape(q_latent, (num_classes, num_queries, -1))  # (N, Q, D)\n","  prototypes = tf.reduce_mean(x_latent, axis=1)  #  prototype for each class (N, D)\n","  # create a list of distances of len N, where the i^{th} element (N, Q) corresponds to distances to prototype of class i \n","  distances_lst = [tf.norm(q_latent - prototypes[i], ord='euclidean', axis=-1)  for i in range(num_classes)]  \n","  distances = tf.stack(distances_lst, axis=-1)  # (N, Q, N)\n","#   distances = tf.linalg.normalize(distances, axis=-1, ord=1)[0]  # normalize distances (l1 norm)\n","   \n","#   if test:\n","#       print(f'x_latent:\\n{x_latent}')\n","#       print(f'q_latent:\\n{q_latent}')\n","    #   print(f'prototypes:\\n{prototypes}')\n","    #   print(f'distances:\\n{distances}')\n","  logits = - tf.reshape(distances, (-1, num_classes))  # logits as negative distances (N * Q, N)\n","  \n","  labels = tf.reshape(labels_onehot, (-1, num_classes))  # (N * Q, N)\n","#   print(f'logits:\\n{logits}')\n","  ce_loss = cross_entropy_loss(logits, labels, k_shot=1)\n","  acc = accuracy(tf.argmax(labels, axis=1), tf.argmax(logits, axis=1))\n","  # compute the prototypes\n","  # compute the distance from the prototypes\n","  # compute cross entropy loss\n","  # note - additional steps are needed!\n","  # return the cross-entropy loss and accuracy\n","\n","  #############################\n","  return ce_loss, acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_bOml4PhkSM"},"source":["# run_ProtoNet\n","from PIL import Image\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import os\n","import glob\n","import matplotlib.pyplot as plt\n","\n","def proto_net_train_step(model, optim, x, q, labels_ph):\n","  num_classes, num_support, im_height, im_width, channels = x.shape\n","  num_queries = q.shape[1]\n","  x = tf.reshape(x, [-1, im_height, im_width, channels])\n","  q = tf.reshape(q, [-1, im_height, im_width, channels])\n","\n","  with tf.GradientTape() as tape:\n","    x_latent = model(x)\n","    q_latent = model(q)\n","    ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n","\n","  gradients = tape.gradient(ce_loss, model.trainable_variables)\n","  optim.apply_gradients(zip(gradients, model.trainable_variables))\n","  return ce_loss, acc\n","\n","def proto_net_eval(model, x, q, labels_ph, test=False):\n","  num_classes, num_support, im_height, im_width, channels = x.shape\n","  num_queries = q.shape[1]\n","  x = tf.reshape(x, [-1, im_height, im_width, channels])\n","  q = tf.reshape(q, [-1, im_height, im_width, channels])\n","\n","  x_latent = model(x)\n","  q_latent = model(q)\n","  ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries, test=test)\n","\n","  return ce_loss, acc \n","\n","def run_protonet(data_path='./omniglot_resized', n_way=20, k_shot=1, n_query=5, n_meta_test_way=20, k_meta_test_shot=5, n_meta_test_query=5):\n","  n_epochs = 20\n","  n_episodes = 100\n","#   n_epochs = 2\n","#   n_episodes = 20\n","\n","  im_width, im_height, channels = 28, 28, 1\n","  num_filters = 32\n","  latent_dim = 16\n","  num_conv_layers = 3\n","  n_meta_test_episodes = 1000\n","#   n_meta_test_episodes = 100\n","\n","  model = ProtoNet([num_filters]*num_conv_layers, latent_dim)\n","  optimizer = tf.keras.optimizers.Adam()\n","\n","    # call DataGenerator with k_shot+n_query samples per class\n","  data_generator = DataGenerator(n_way, k_shot+n_query, n_meta_test_way, k_meta_test_shot+n_meta_test_query)\n","  for ep in range(n_epochs):\n","    for epi in range(n_episodes):\n","      #############################\n","      #### YOUR CODE GOES HERE ####\n","      X_tr, y_tr = data_generator.sample_batch('meta_train', batch_size=1)  # [1, N,  k_shot+n_query, 784]  [1, N,  k_shot+n_query , N]\n","      X_tr, y_tr = X_tr[0], y_tr[0]  # [N,  k_shot+n_query, 784]  [N,  k_shot+n_query , N]\n","      X_tr = tf.reshape(X_tr, (n_way, k_shot+n_query, im_width, im_height, channels))  # [N, k_shot+n_query, 28, 28, 1]\n","      support = X_tr[:, :k_shot, :, :, :]  # [N, K_shot, 28, 28, 1]\n","      query = X_tr[:, k_shot:, :, :, :]  # [N, n_query, 28, 28, 1]\n","      labels = y_tr[:, k_shot:, :]  # [N, n_query , N]\n","      # sample a batch of training data and partition it into\n","      # support and query sets\n","\n","      #############################\n","      ls, ac = proto_net_train_step(model, optimizer, x=support, q=query, labels_ph=labels)\n","      if (epi+1) % 50 == 0:\n","        #############################\n","        #### YOUR CODE GOES HERE ####\n","        X_val, y_val = data_generator.sample_batch('meta_val', batch_size=1)  # [1 N,  k_shot+n_query, 784]  [1, N,  k_shot+n_query , N]\n","        X_val, y_val = X_val[0], y_val[0]  # [N,  k_shot+n_query, 784]  [N,  k_shot+n_query , N]\n","        X_val = tf.reshape(X_val, (n_way, k_shot+n_query, im_width, im_height, channels))  # [N, k_shot+n_query, 28, 28, 1]\n","        support = X_val[:, :k_shot, :, :, :]  # [N, K_shot, 28, 28, 1]\n","        query = X_val[:, k_shot:, :, :, :]  # [N, n_query, 28, 28, 1]\n","        labels = y_val[:, k_shot:, :]  # [N, n_query , N]\n","        # sample a batch of validation data and partition it into\n","        # support and query sets\n","\n","        #############################\n","        val_ls, val_ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n","        print('[epoch {}/{}, episode {}/{}] => meta-training loss: {:.5f}, meta-training acc: {:.5f}, meta-val loss: {:.5f}, meta-val acc: {:.5f}'.format(ep+1,\n","                                                                    n_epochs,\n","                                                                    epi+1,\n","                                                                    n_episodes,\n","                                                                    ls,\n","                                                                    ac,\n","                                                                    val_ls,\n","                                                                    val_ac))\n","\n","  print('Testing...')\n","  meta_test_accuracies = []\n","  for epi in range(n_meta_test_episodes):\n","    #############################\n","    #### YOUR CODE GOES HERE ####\n","    X_ts, y_ts = data_generator.sample_batch('meta_test', batch_size=1)  \n","    X_ts, y_ts = X_ts[0], y_ts[0]\n","    X_ts = tf.reshape(X_ts, (n_meta_test_way, k_meta_test_shot+n_meta_test_query, im_width, im_height, channels))  # [N, k_shot+n_query, 28, 28, 1]\n","    support = X_ts[:, :k_meta_test_shot, :, :, :]  # [N, k_meta_test_shot, 28, 28, 1]\n","    query = X_ts[:, k_meta_test_shot:, :, :, :]  # [N, n_meta_test_query, 28, 28, 1]\n","    labels = y_ts[:, k_meta_test_shot:, :]  # [N, n_query , N]\n","    # sample a batch of test data and partition it into\n","    # support and query sets\n","\n","    #############################\n","    ls, ac = proto_net_eval(model, x=support, q=query, labels_ph=labels, test=True)\n","    meta_test_accuracies.append(ac)\n","    if (epi+1) % 50 == 0:\n","      print('[meta-test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_meta_test_episodes, ls, ac))\n","  avg_acc = np.mean(meta_test_accuracies)\n","  stds = np.std(meta_test_accuracies)\n","  print('Average Meta-Test Accuracy: {:.5f}, Meta-Test Accuracy Std: {:.5f}'.format(avg_acc, stds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6Tv12fbTQqJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632236077034,"user_tz":-180,"elapsed":191283,"user":{"displayName":"Gal Kampel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13734932312114013687"}},"outputId":"cf9505fb-09f5-4d6e-a2d2-7000de3b6f0b"},"source":["run_protonet('./omniglot_resized/', n_way=5, k_shot=1, n_query=5, n_meta_test_way=5, k_meta_test_shot=4, n_meta_test_query=4)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[epoch 1/20, episode 50/100] => meta-training loss: 1.60772, meta-training acc: 0.16000, meta-val loss: 1.61468, meta-val acc: 0.20000\n","[epoch 1/20, episode 100/100] => meta-training loss: 1.61509, meta-training acc: 0.12000, meta-val loss: 1.56732, meta-val acc: 0.40000\n","[epoch 2/20, episode 50/100] => meta-training loss: 1.60629, meta-training acc: 0.12000, meta-val loss: 1.60006, meta-val acc: 0.24000\n","[epoch 2/20, episode 100/100] => meta-training loss: 1.61034, meta-training acc: 0.28000, meta-val loss: 1.61714, meta-val acc: 0.12000\n","[epoch 3/20, episode 50/100] => meta-training loss: 1.60399, meta-training acc: 0.28000, meta-val loss: 1.61148, meta-val acc: 0.12000\n","[epoch 3/20, episode 100/100] => meta-training loss: 1.62096, meta-training acc: 0.16000, meta-val loss: 1.60626, meta-val acc: 0.16000\n","[epoch 4/20, episode 50/100] => meta-training loss: 1.61806, meta-training acc: 0.12000, meta-val loss: 1.59693, meta-val acc: 0.36000\n","[epoch 4/20, episode 100/100] => meta-training loss: 1.59497, meta-training acc: 0.28000, meta-val loss: 1.61199, meta-val acc: 0.08000\n","[epoch 5/20, episode 50/100] => meta-training loss: 1.61129, meta-training acc: 0.08000, meta-val loss: 1.62264, meta-val acc: 0.00000\n","[epoch 5/20, episode 100/100] => meta-training loss: 1.60678, meta-training acc: 0.40000, meta-val loss: 1.60788, meta-val acc: 0.24000\n","[epoch 6/20, episode 50/100] => meta-training loss: 1.62475, meta-training acc: 0.08000, meta-val loss: 1.61246, meta-val acc: 0.16000\n","[epoch 6/20, episode 100/100] => meta-training loss: 1.60807, meta-training acc: 0.20000, meta-val loss: 1.61707, meta-val acc: 0.32000\n","[epoch 7/20, episode 50/100] => meta-training loss: 1.58517, meta-training acc: 0.24000, meta-val loss: 1.61099, meta-val acc: 0.28000\n","[epoch 7/20, episode 100/100] => meta-training loss: 1.61415, meta-training acc: 0.28000, meta-val loss: 1.62192, meta-val acc: 0.08000\n","[epoch 8/20, episode 50/100] => meta-training loss: 1.60478, meta-training acc: 0.28000, meta-val loss: 1.60981, meta-val acc: 0.04000\n","[epoch 8/20, episode 100/100] => meta-training loss: 1.61044, meta-training acc: 0.16000, meta-val loss: 1.60374, meta-val acc: 0.36000\n","[epoch 9/20, episode 50/100] => meta-training loss: 1.61127, meta-training acc: 0.12000, meta-val loss: 1.60143, meta-val acc: 0.36000\n","[epoch 9/20, episode 100/100] => meta-training loss: 1.60885, meta-training acc: 0.20000, meta-val loss: 1.61193, meta-val acc: 0.16000\n","[epoch 10/20, episode 50/100] => meta-training loss: 1.61361, meta-training acc: 0.16000, meta-val loss: 1.62013, meta-val acc: 0.16000\n","[epoch 10/20, episode 100/100] => meta-training loss: 1.60506, meta-training acc: 0.36000, meta-val loss: 1.61865, meta-val acc: 0.04000\n","[epoch 11/20, episode 50/100] => meta-training loss: 1.59896, meta-training acc: 0.28000, meta-val loss: 1.60401, meta-val acc: 0.44000\n","[epoch 11/20, episode 100/100] => meta-training loss: 1.61508, meta-training acc: 0.04000, meta-val loss: 1.61724, meta-val acc: 0.00000\n","[epoch 12/20, episode 50/100] => meta-training loss: 1.61330, meta-training acc: 0.04000, meta-val loss: 1.60328, meta-val acc: 0.32000\n","[epoch 12/20, episode 100/100] => meta-training loss: 1.61895, meta-training acc: 0.08000, meta-val loss: 1.60521, meta-val acc: 0.40000\n","[epoch 13/20, episode 50/100] => meta-training loss: 1.61328, meta-training acc: 0.08000, meta-val loss: 1.61649, meta-val acc: 0.16000\n","[epoch 13/20, episode 100/100] => meta-training loss: 1.60009, meta-training acc: 0.40000, meta-val loss: 1.61237, meta-val acc: 0.20000\n","[epoch 14/20, episode 50/100] => meta-training loss: 1.60840, meta-training acc: 0.16000, meta-val loss: 1.60842, meta-val acc: 0.24000\n","[epoch 14/20, episode 100/100] => meta-training loss: 1.61436, meta-training acc: 0.24000, meta-val loss: 1.61495, meta-val acc: 0.24000\n","[epoch 15/20, episode 50/100] => meta-training loss: 1.61707, meta-training acc: 0.12000, meta-val loss: 1.60807, meta-val acc: 0.20000\n","[epoch 15/20, episode 100/100] => meta-training loss: 1.59984, meta-training acc: 0.24000, meta-val loss: 1.60181, meta-val acc: 0.24000\n","[epoch 16/20, episode 50/100] => meta-training loss: 1.58611, meta-training acc: 0.32000, meta-val loss: 1.60789, meta-val acc: 0.28000\n","[epoch 16/20, episode 100/100] => meta-training loss: 1.60831, meta-training acc: 0.12000, meta-val loss: 1.61289, meta-val acc: 0.12000\n","[epoch 17/20, episode 50/100] => meta-training loss: 1.59912, meta-training acc: 0.40000, meta-val loss: 1.61136, meta-val acc: 0.20000\n","[epoch 17/20, episode 100/100] => meta-training loss: 1.60163, meta-training acc: 0.24000, meta-val loss: 1.61273, meta-val acc: 0.16000\n","[epoch 18/20, episode 50/100] => meta-training loss: 1.60983, meta-training acc: 0.20000, meta-val loss: 1.61582, meta-val acc: 0.20000\n","[epoch 18/20, episode 100/100] => meta-training loss: 1.60944, meta-training acc: 0.20000, meta-val loss: 1.60944, meta-val acc: 0.20000\n","[epoch 19/20, episode 50/100] => meta-training loss: 1.60944, meta-training acc: 0.20000, meta-val loss: 1.60944, meta-val acc: 0.20000\n","[epoch 19/20, episode 100/100] => meta-training loss: 1.60944, meta-training acc: 0.20000, meta-val loss: 1.60944, meta-val acc: 0.20000\n","[epoch 20/20, episode 50/100] => meta-training loss: 1.60944, meta-training acc: 0.20000, meta-val loss: 1.60944, meta-val acc: 0.20000\n","[epoch 20/20, episode 100/100] => meta-training loss: 1.60944, meta-training acc: 0.20000, meta-val loss: 1.60944, meta-val acc: 0.20000\n","Testing...\n","[meta-test episode 50/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 100/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 150/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 200/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 250/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 300/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 350/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 400/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 450/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 500/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 550/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 600/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 650/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 700/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 750/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 800/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 850/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 900/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 950/1000] => loss: 1.60944, acc: 0.20000\n","[meta-test episode 1000/1000] => loss: 1.60944, acc: 0.20000\n","Average Meta-Test Accuracy: 0.20000, Meta-Test Accuracy Std: 0.00000\n"]}]},{"cell_type":"code","metadata":{"id":"J9IoWm36heMu"},"source":["    "],"execution_count":null,"outputs":[]}]}